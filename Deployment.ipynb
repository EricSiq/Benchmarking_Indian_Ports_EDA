{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricSiq/Benchmarking_Indian_Ports_EDA/blob/main/Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54arw8jHIfiY",
        "outputId": "94585084-6a44-4edf-831f-abdc3e390574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "rGc3nBl4IzBx",
        "outputId": "3735253f-f469-4225-d73a-37eea313d164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21d61614-7dbf-4f2d-82b1-3092ba233550\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21d61614-7dbf-4f2d-82b1-3092ba233550\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving capacity.csv to capacity.csv\n",
            "Saving Output-per-Ship-Berth-Day.csv to Output-per-Ship-Berth-Day.csv\n",
            "Saving pre-berthing detention.csv to pre-berthing detention.csv\n",
            "Saving traffic.csv to traffic.csv\n",
            "Saving TRT.csv to TRT.csv\n",
            "Saving utilization.csv to utilization.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Load your datasets\n",
        "trt_df = pd.read_csv('/content/TRT.csv')\n",
        "traffic_df = pd.read_csv('/content/traffic.csv')\n",
        "capacity_df = pd.read_csv('/content/capacity.csv')\n",
        "utilization_df = pd.read_csv('/content/utilization.csv')\n",
        "pre_berthing_df = pd.read_csv('/content/pre-berthing detention.csv')\n",
        "output_df = pd.read_csv('/content/Output-per-Ship-Berth-Day.csv')\n",
        "\n",
        "# Function to plot metric trends\n",
        "def plot_metric_trends(metric_df, metric_name):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for port in [col for col in metric_df.columns if col not in ['Year', 'All Ports']]:\n",
        "        plt.plot(metric_df['Year'], metric_df[port], label=port)\n",
        "    plt.title(f'{metric_name} Trends Across Ports')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()\n",
        "\n",
        "# Functions to generate plots for each metric\n",
        "def show_capacity_trends():\n",
        "    return plot_metric_trends(capacity_df, \"Capacity\")\n",
        "\n",
        "def show_utilization_trends():\n",
        "    return plot_metric_trends(utilization_df, \"Utilization\")\n",
        "\n",
        "def show_trt_trends():\n",
        "    return plot_metric_trends(trt_df, \"TRT\")\n",
        "\n",
        "def show_output_trends():\n",
        "    return plot_metric_trends(output_df, \"Output\")\n",
        "\n",
        "def show_pre_berthing_trends():\n",
        "    return plot_metric_trends(pre_berthing_df, \"Pre-Berthing\")\n",
        "\n",
        "# Mapping of metric names to functions\n",
        "metric_to_function = {\n",
        "    \"Capacity\": show_capacity_trends,\n",
        "    \"Utilization\": show_utilization_trends,\n",
        "    \"TRT\": show_trt_trends,\n",
        "    \"Output\": show_output_trends,\n",
        "    \"Pre-Berthing\": show_pre_berthing_trends\n",
        "}\n",
        "\n",
        "# Function to analyze correlations for a specific port\n",
        "def analyze_port_correlations(port_name):\n",
        "    if port_name not in capacity_df.columns:\n",
        "        return f\"Port {port_name} not found in data.\"\n",
        "\n",
        "    try:\n",
        "        metrics = {\n",
        "            'Capacity': capacity_df.get(port_name),\n",
        "            'Traffic': traffic_df.get(port_name),\n",
        "            'Utilization': utilization_df.get(port_name),\n",
        "            'TRT': trt_df.get(port_name),\n",
        "            'Output': output_df.get(port_name)\n",
        "        }\n",
        "\n",
        "        for key, series in metrics.items():\n",
        "            if series is None or series.isna().all():\n",
        "                return f\"Data for {key} is missing or not valid for {port_name}.\"\n",
        "\n",
        "        for key in metrics:\n",
        "            metrics[key] = pd.to_numeric(metrics[key], errors='coerce')\n",
        "\n",
        "        correlation_df = pd.DataFrame(metrics).dropna()\n",
        "        if correlation_df.shape[0] < 2:\n",
        "            return \"Not enough valid data for correlation analysis.\"\n",
        "\n",
        "        return correlation_df.corr()\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating correlations: {str(e)}\"\n",
        "\n",
        "def get_correlation_data(port_name):\n",
        "    result = analyze_port_correlations(port_name)\n",
        "    if isinstance(result, str):\n",
        "        return result\n",
        "    return result\n",
        "\n",
        "# List of port names\n",
        "port_names = list(capacity_df.columns)\n",
        "\n",
        "# Creating the Gradio interfaces\n",
        "iface_trends = gr.Interface(\n",
        "    fn=lambda metric: metric_to_function[metric](),\n",
        "    inputs=gr.Dropdown(choices=[\"Capacity\", \"Utilization\", \"TRT\", \"Output\", \"Pre-Berthing\"], label=\"Select Metric\"),\n",
        "    outputs=gr.Plot(label=\"Metric Trends\"),\n",
        "    title=\"Port Performance Analysis\",\n",
        "    description=\"Select a metric to view trends across ports over the years.\"\n",
        ")\n",
        "\n",
        "iface_correlation = gr.Interface(\n",
        "    fn=get_correlation_data,\n",
        "    inputs=gr.Dropdown(choices=port_names, label=\"Select Port\"),\n",
        "    outputs=gr.Dataframe(label=\"Correlation Matrix\"),\n",
        "    title=\"Port Correlation Analysis\",\n",
        "    description=\"Select a port to view the correlation matrix of capacity, traffic, utilization, TRT, and output.\"\n",
        ")\n",
        "\n",
        "def plot_port_comparison(metric_df, year, metric_name):\n",
        "    try:\n",
        "        metric_df['Year'] = metric_df['Year'].astype(str)\n",
        "        year_data = metric_df[metric_df['Year'] == year].melt(\n",
        "            id_vars=['Year'],\n",
        "            value_vars=[col for col in metric_df.columns if col not in ['Year', 'All Ports']]\n",
        "        )\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        sns.barplot(x='variable', y='value', data=year_data)\n",
        "        plt.title(f'{metric_name} Comparison Across Ports ({year})')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.xlabel('Ports')\n",
        "        plt.ylabel(metric_name)\n",
        "        plt.tight_layout()\n",
        "        return plt.gcf()\n",
        "    except Exception as e:\n",
        "        return f\"Error generating plot for {metric_name}: {str(e)}\"\n",
        "\n",
        "def show_comparison_plots(year):\n",
        "    try:\n",
        "        year = str(year)\n",
        "        fig1 = plot_port_comparison(capacity_df, year, 'Capacity')\n",
        "        fig2 = plot_port_comparison(traffic_df, year, 'Traffic')\n",
        "        fig3 = plot_port_comparison(utilization_df, year, 'Utilization')\n",
        "        fig4 = plot_port_comparison(trt_df, year, 'TRT')\n",
        "        fig5 = plot_port_comparison(output_df, year, 'Output')\n",
        "        fig6 = plot_port_comparison(pre_berthing_df, year, 'Pre-Berthing')\n",
        "        return [fig1, fig2, fig3, fig4, fig5, fig6]\n",
        "    except Exception as e:\n",
        "        return f\"Error showing comparison plots: {str(e)}\"\n",
        "\n",
        "years = capacity_df['Year'].unique()\n",
        "\n",
        "iface_comparison = gr.Interface(\n",
        "    fn=show_comparison_plots,\n",
        "    inputs=gr.Dropdown(choices=[str(year) for year in years], label=\"Select Year\"),\n",
        "    outputs=[gr.Plot(label=\"Capacity\"), gr.Plot(label=\"Traffic\"), gr.Plot(label=\"Utilization\"),\n",
        "             gr.Plot(label=\"TRT\"), gr.Plot(label=\"Output\"), gr.Plot(label=\"Pre-Berthing\")],\n",
        "    title=\"Port Comparison Analysis\",\n",
        "    description=\"Select a year to compare different metrics across ports.\"\n",
        ")\n",
        "\n",
        "# Function for TRT performance analysis\n",
        "def analyze_trt_performance():\n",
        "    port_cols = [col for col in trt_df.columns if col not in ['Year', 'All Ports']]\n",
        "    avg_trt = trt_df[port_cols].mean().sort_values()\n",
        "\n",
        "    trt_trend = trt_df[port_cols].apply(lambda x: stats.linregress(range(len(x)), x)[0])\n",
        "\n",
        "    performance_summary = pd.DataFrame({\n",
        "        'Average_TRT': avg_trt,\n",
        "        'TRT_Trend': trt_trend\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=avg_trt.index, y=avg_trt.values)\n",
        "    plt.title('Average Turn Round Time by Port')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Average TRT (days)')\n",
        "    plt.xlabel('Port')\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()\n",
        "\n",
        "iface_trt_performance = gr.Interface(\n",
        "    fn=analyze_trt_performance,\n",
        "    inputs=None,\n",
        "    outputs=gr.Plot(label=\"TRT Performance Graph\"),\n",
        "    title=\"TRT Performance Analysis\",\n",
        "    description=\"Displays the average Turn Round Time (TRT) by port with a trend analysis.\"\n",
        ")\n",
        "\n",
        "# Function for Output Efficiency Analysis\n",
        "def analyze_output_efficiency():\n",
        "    port_cols = [col for col in output_df.columns if col not in ['Year', 'All Ports']]\n",
        "    avg_output = output_df[port_cols].mean()\n",
        "    avg_capacity = capacity_df[port_cols].mean()\n",
        "    efficiency_ratio = (avg_output / avg_capacity).sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(avg_capacity, avg_output)\n",
        "    for i, port in enumerate(port_cols):\n",
        "        plt.annotate(port, (avg_capacity[port], avg_output[port]))\n",
        "    plt.xlabel('Average Capacity')\n",
        "    plt.ylabel('Average Output per Ship Berth Day')\n",
        "    plt.title('Port Output Efficiency vs Capacity')\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()\n",
        "\n",
        "iface_output_efficiency = gr.Interface(\n",
        "    fn=analyze_output_efficiency,\n",
        "    inputs=None,\n",
        "    outputs=gr.Plot(label=\"Output Efficiency Scatter Plot\"),\n",
        "    title=\"Output Efficiency Analysis\",\n",
        "    description=\"Scatter plot of average capacity vs. average output per ship berth day, with port labels.\"\n",
        ")\n",
        "\n",
        "# Function for Capacity Utilization Analysis\n",
        "def analyze_capacity_utilization():\n",
        "    port_cols = [col for col in utilization_df.columns if col not in ['Year', 'All Ports']]\n",
        "\n",
        "    util_stats = pd.DataFrame({\n",
        "        'Mean_Utilization': utilization_df[port_cols].mean(),\n",
        "        'Std_Utilization': utilization_df[port_cols].std(),\n",
        "        'Max_Utilization': utilization_df[port_cols].max(),\n",
        "        'Min_Utilization': utilization_df[port_cols].min()\n",
        "    }).sort_values('Mean_Utilization', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for port in util_stats.index:\n",
        "        plt.vlines(x=port,\n",
        "                  ymin=util_stats.loc[port, 'Min_Utilization'],\n",
        "                  ymax=util_stats.loc[port, 'Max_Utilization'],\n",
        "                  color='gray', alpha=0.5)\n",
        "        plt.plot(port, util_stats.loc[port, 'Mean_Utilization'], 'bo')\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Utilization Rate (%)')\n",
        "    plt.title('Port Capacity Utilization Ranges')\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()\n",
        "\n",
        "iface_capacity_utilization = gr.Interface(\n",
        "    fn=analyze_capacity_utilization,\n",
        "    inputs=None,\n",
        "    outputs=gr.Plot(label=\"Capacity Utilization Graph\"),\n",
        "    title=\"Capacity Utilization Analysis\",\n",
        "    description=\"Displays the range of utilization rates for different ports, with port names on the x-axis.\"\n",
        ")\n",
        "\n",
        "# Function for Geographical Performance Analysis\n",
        "def analyze_geographical_performance1():\n",
        "    east_coast = ['Kolkata', 'Haldia', 'Paradip', 'Vishakhapatnam', 'Ennore', 'Chennai']\n",
        "    west_coast = ['Kandla', 'Mumbai', 'J.L.Nehru', 'Mormugoa', 'New Mangalore', 'Cochin']\n",
        "\n",
        "    east_output = output_df[east_coast].mean()\n",
        "    west_output = output_df[west_coast].mean()\n",
        "\n",
        "    output_comparison = pd.DataFrame({\n",
        "        'East Coast': east_output,\n",
        "        'West Coast': west_output\n",
        "    }).T  # Transpose so that we have \"East Coast\" and \"West Coast\" as rows\n",
        "\n",
        "    output_comparison.plot(kind='bar', stacked=True, figsize=(12, 7), colormap='tab20')\n",
        "    plt.title('East Coast vs West Coast Port Performance (Output Only)')\n",
        "    plt.ylabel('Average Output Value')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.legend(title=\"Ports\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    return plt.gcf()\n",
        "\n",
        "iface_geographical_performance = gr.Interface(\n",
        "    fn=analyze_geographical_performance1,\n",
        "    inputs=None,\n",
        "    outputs=gr.Plot(label=\"Geographical Performance Graph\"),\n",
        "    title=\"Geographical Performance Analysis\",\n",
        "    description=\"Displays a stacked bar graph comparing the average output of East and West Coast ports.\"\n",
        ")\n",
        "\n",
        "# Function for Overall Traffic Growth Analysis\n",
        "def analyze_overall_traffic_growth():\n",
        "    traffic_df['Total Traffic'] = traffic_df.drop(columns='Year').sum(axis=1)\n",
        "    traffic_df['Traffic Growth'] = traffic_df['Total Traffic'].pct_change() * 100\n",
        "\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    plt.plot(traffic_df['Year'], traffic_df['Traffic Growth'], marker='o', color='teal', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Year', fontsize=12)\n",
        "    plt.ylabel('Traffic Growth (%)', fontsize=12)\n",
        "    plt.title('Overall Traffic Growth Across All Ports per Year', fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    for x, y in zip(traffic_df['Year'], traffic_df['Traffic Growth']):\n",
        "        if not pd.isna(y):\n",
        "            plt.annotate(f'{y:.1f}%',\n",
        "                         (x, y),\n",
        "                         textcoords=\"offset points\",\n",
        "                         xytext=(0,10),\n",
        "                         ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()\n",
        "\n",
        "iface_traffic_growth = gr.Interface(\n",
        "    fn=analyze_overall_traffic_growth,\n",
        "    inputs=None,\n",
        "    outputs=gr.Plot(label=\"Traffic Growth Graph\"),\n",
        "    title=\"Overall Traffic Growth Analysis\",\n",
        "    description=\"Displays the overall traffic growth of all major ports across the years.\"\n",
        ")\n",
        "\n",
        "# Combine all interfaces using Gradio Tabs\n",
        "app = gr.TabbedInterface(\n",
        "    [iface_trends, iface_correlation, iface_comparison, iface_trt_performance, iface_output_efficiency, iface_capacity_utilization, iface_geographical_performance, iface_traffic_growth],\n",
        "    tab_names=[\"Metric Trends\", \"Correlation Analysis\", \"Port Comparison\", \"TRT Performance\", \"Output Efficiency\", \"Capacity Utilization\", \"Geographical Performance\", \"Traffic Growth\"]\n",
        ")\n",
        "\n",
        "# Launch the combined app\n",
        "app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "VcL5x68cIg9R",
        "outputId": "51915d51-bf6e-4a56-fe9b-04eaa586f6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://872fd430db1e0c7260.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://872fd430db1e0c7260.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}